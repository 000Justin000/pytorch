(pytorch) andrewor:~/local/pytorch$ python test/test_quantization.py TestQuantizeDBRIndividualOps.test_conv_transpose_functional
============================== FX GRAPH
 graph(%self : __torch__.torch.fx.graph_module.GraphModule,
      %x : Float(3, 1, 10, 10, strides=[100, 100, 10, 1], requires_grad=0, device=cpu)):
  %bias : Tensor = prim::GetAttr[name="bias"](%self)
  %weight : Tensor = prim::GetAttr[name="weight"](%self)
  %6 : int = prim::Constant[value=1]() # <eval_with_key>.46:7:0
  %7 : int = prim::Constant[value=1]() # <eval_with_key>.46:7:0
  %8 : int[] = prim::ListConstruct(%6, %7)
  %9 : int = prim::Constant[value=0]() # <eval_with_key>.46:7:0
  %10 : int = prim::Constant[value=0]() # <eval_with_key>.46:7:0
  %11 : int[] = prim::ListConstruct(%9, %10)
  %12 : int = prim::Constant[value=1]() # <eval_with_key>.46:7:0
  %13 : int = prim::Constant[value=1]() # <eval_with_key>.46:7:0
  %14 : int[] = prim::ListConstruct(%12, %13)
  %15 : bool = prim::Constant[value=1]() # <eval_with_key>.46:7:0
  %16 : int = prim::Constant[value=0]() # <eval_with_key>.46:7:0
  %17 : int = prim::Constant[value=0]() # <eval_with_key>.46:7:0
  %18 : int[] = prim::ListConstruct(%16, %17)
  %19 : int = prim::Constant[value=1]() # <eval_with_key>.46:7:0
  %20 : bool = prim::Constant[value=0]() # <eval_with_key>.46:7:0
  %21 : bool = prim::Constant[value=0]() # <eval_with_key>.46:7:0
  %22 : bool = prim::Constant[value=1]() # <eval_with_key>.46:7:0
  %23 : bool = prim::Constant[value=1]() # <eval_with_key>.46:7:0
  %24 : Float(3, 3, 19, 19, strides=[1083, 361, 19, 1], requires_grad=0, device=cpu) = aten::_convolution(%x, %weight, %bias, %8, %11, %14, %15, %18, %19, %20, %21, %22, %23) # <eval_with_key>.46:7:0
  return (%24)

/data/users/andrewor/pytorch/torch/_tensor.py:1142: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  ret = func(*args, **kwargs)
=============================== DBR GRAPH
 graph(%self : __torch__.torch.fx.graph_module.___torch_mangle_0.QuantizationDispatchModule,
      %x : Float(3, 1, 10, 10, strides=[100, 100, 10, 1], requires_grad=0, device=cpu)):
  %_packed_params_0 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params_0"](%self)
  %7 : float = prim::Constant[value=0.046993616968393326]() # <eval_with_key>.47:7:0
  %8 : int = prim::Constant[value=77]() # <eval_with_key>.47:7:0
  %9 : int = prim::Constant[value=13]() # <eval_with_key>.47:7:0
  %quantize_per_tensor : QUInt8(3, 1, 10, 10, strides=[100, 100, 10, 1], requires_grad=0, device=cpu) = aten::quantize_per_tensor(%x, %7, %8, %9) # <eval_with_key>.47:7:0
  %11 : float = prim::Constant[value=0.36115631461143494]() # <eval_with_key>.47:9:0
  %12 : int = prim::Constant[value=63]() # <eval_with_key>.47:9:0
  %conv_transpose2d : QUInt8(3, 3, 19, 19, strides=[1083, 1, 57, 3], requires_grad=0, device=cpu) = quantized::conv_transpose2d(%quantize_per_tensor, %_packed_params_0, %11, %12) # <eval_with_key>.47:9:0
  %14 : Float(3, 3, 19, 19, strides=[1083, 1, 57, 3], requires_grad=0, device=cpu) = aten::dequantize(%conv_transpose2d) # <eval_with_key>.47:10:0
  return (%14)

.
----------------------------------------------------------------------
Ran 1 test in 0.247s

OK

(pytorch) andrewor:~/local/pytorch$ python test/test_quantization.py TestQuantizeDBRIndividualOps.test_conv_functional
/data/users/andrewor/pytorch/torch/fx/graph.py:1156: UserWarning: Node _packed_weight_0 target _packed_weight_0 _packed_weight_0 of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target
  warnings.warn(f'Node {node} target {node.target} {atom} of {seen_qualname} does '
<eval_with_key>.48:11: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  conv2d = torch.ops.quantized.conv2d(quantize_per_tensor, _packed_weight_0, _scale_0, _zero_point_0);  quantize_per_tensor = _packed_weight_0 = _scale_0 = _zero_point_0 = None
============================== FX GRAPH
 graph(%self : __torch__.torch.fx.graph_module.GraphModule,
      %x : Float(1, 3, 10, 10, strides=[300, 100, 10, 1], requires_grad=0, device=cpu)):
  %_packed_weight_0 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_weight_0"](%self)
  %_input_zero_point_0 : Tensor = prim::GetAttr[name="_input_zero_point_0"](%self)
  %_input_scale_0 : Tensor = prim::GetAttr[name="_input_scale_0"](%self)
  %9 : int = prim::Constant[value=13]() # <eval_with_key>.48:7:0
  %quantize_per_tensor : QUInt8(1, 3, 10, 10, strides=[300, 100, 10, 1], requires_grad=0, device=cpu) = aten::quantize_per_tensor(%x, %_input_scale_0, %_input_zero_point_0, %9) # <eval_with_key>.48:7:0
  %11 : float = prim::Constant[value=2.3707172870635986]() # <eval_with_key>.48:11:0
  %12 : int = prim::Constant[value=0]() # <eval_with_key>.48:11:0
  %conv2d : QUInt8(1, 1, 1, 1, strides=[1, 1, 1, 1], requires_grad=0, device=cpu) = quantized::conv2d(%quantize_per_tensor, %_packed_weight_0, %11, %12) # <eval_with_key>.48:11:0
  %14 : Float(1, 1, 1, 1, strides=[1, 1, 1, 1], requires_grad=0, device=cpu) = aten::dequantize(%conv2d) # <eval_with_key>.48:12:0
  return (%14)

/data/users/andrewor/pytorch/torch/_tensor.py:1142: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  ret = func(*args, **kwargs)
=============================== DBR GRAPH
 graph(%self : __torch__.torch.fx.graph_module.___torch_mangle_0.QuantizationDispatchModule,
      %x : Float(1, 3, 10, 10, strides=[300, 100, 10, 1], requires_grad=0, device=cpu)):
  %_packed_params_0 : __torch__.torch.classes.quantized.Conv2dPackedParamsBase = prim::GetAttr[name="_packed_params_0"](%self)
  %7 : float = prim::Constant[value=0.060189440846443176]() # <eval_with_key>.49:7:0
  %8 : int = prim::Constant[value=59]() # <eval_with_key>.49:7:0
  %9 : int = prim::Constant[value=13]() # <eval_with_key>.49:7:0
  %quantize_per_tensor : QUInt8(1, 3, 10, 10, strides=[300, 100, 10, 1], requires_grad=0, device=cpu) = aten::quantize_per_tensor(%x, %7, %8, %9) # <eval_with_key>.49:7:0
  %11 : float = prim::Constant[value=2.3707172870635986]() # <eval_with_key>.49:9:0
  %12 : int = prim::Constant[value=0]() # <eval_with_key>.49:9:0
  %conv2d : QUInt8(1, 1, 1, 1, strides=[1, 1, 1, 1], requires_grad=0, device=cpu) = quantized::conv2d(%quantize_per_tensor, %_packed_params_0, %11, %12) # <eval_with_key>.49:9:0
  %14 : Float(1, 1, 1, 1, strides=[1, 1, 1, 1], requires_grad=0, device=cpu) = aten::dequantize(%conv2d) # <eval_with_key>.49:10:0
  return (%14)

.
----------------------------------------------------------------------
Ran 1 test in 0.247s

OK
