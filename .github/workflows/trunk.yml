name: trunk

on:
  push:
    branches:
      - master
      - main
      - release/*
    tags:
      - ciflow/trunk/*
      - ciflow/all/*
  workflow_dispatch:

concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.sha }}-${{ github.event_name == 'workflow_dispatch' }}
  cancel-in-progress: true

jobs:
  parallelnative-linux-xenial-py3_7-gcc5_4-build:
    name: parallelnative-linux-xenial-py3.7-gcc5.4
    uses: ./.github/workflows/_linux-build.yml
    with:
      build-environment: parallelnative-linux-xenial-py3.7-gcc5.4
      docker-image-name: pytorch-linux-xenial-py3.7-gcc5.4

  parallelnative-linux-xenial-py3_7-gcc5_4-test:
    name: parallelnative-linux-xenial-py3.7-gcc5.4
    uses: ./.github/workflows/_linux-test.yml
    needs: parallelnative-linux-xenial-py3_7-gcc5_4-build
    with:
      build-environment: parallelnative-linux-xenial-py3.7-gcc5.4
      docker-image: ${{ needs.parallelnative-linux-xenial-py3_7-gcc5_4-build.outputs.docker-image }}
      test-matrix: |
        { include: [
          { config: "default", shard: 1, num_shards: 1, runner: "linux.2xlarge" },

          { config: "default", shard: 1, num_shards: 2, runner: "linux.2xlarge" },
          { config: "default", shard: 2, num_shards: 2, runner: "linux.2xlarge" },

          { config: "default", shard: 1, num_shards: 3, runner: "linux.2xlarge" },
          { config: "default", shard: 2, num_shards: 3, runner: "linux.2xlarge" },
          { config: "default", shard: 3, num_shards: 3, runner: "linux.2xlarge" },
        ]}

  linux-bionic-cuda10_2-py3_9-gcc7-build:
    name: linux-bionic-cuda10.2-py3.9-gcc7
    uses: ./.github/workflows/_linux-build.yml
    with:
      build-environment: linux-bionic-cuda10.2-py3.9-gcc7
      docker-image-name: pytorch-linux-bionic-cuda10.2-cudnn7-py3.9-gcc7

  linux-bionic-cuda10_2-py3_9-gcc7-test:
    name: linux-bionic-cuda10.2-py3.9-gcc7
    uses: ./.github/workflows/_linux-test.yml
    needs: linux-bionic-cuda10_2-py3_9-gcc7-build
    with:
      build-environment: linux-bionic-cuda10.2-py3.9-gcc7
      docker-image: ${{ needs.linux-bionic-cuda10_2-py3_9-gcc7-build.outputs.docker-image }}
      test-matrix: |
        { include: [
          { config: "default", shard: 1, num_shards: 1, runner: "linux.4xlarge.nvidia.gpu" },

          { config: "default", shard: 1, num_shards: 2, runner: "linux.4xlarge.nvidia.gpu" },
          { config: "default", shard: 2, num_shards: 2, runner: "linux.4xlarge.nvidia.gpu" },

          { config: "default", shard: 1, num_shards: 3, runner: "linux.4xlarge.nvidia.gpu" },
          { config: "default", shard: 2, num_shards: 3, runner: "linux.4xlarge.nvidia.gpu" },
          { config: "default", shard: 3, num_shards: 3, runner: "linux.4xlarge.nvidia.gpu" },

          { config: "default", shard: 1, num_shards: 4, runner: "linux.4xlarge.nvidia.gpu" },
          { config: "default", shard: 2, num_shards: 4, runner: "linux.4xlarge.nvidia.gpu" },
          { config: "default", shard: 3, num_shards: 4, runner: "linux.4xlarge.nvidia.gpu" },
          { config: "default", shard: 4, num_shards: 4, runner: "linux.4xlarge.nvidia.gpu" },

          { config: "default", shard: 1, num_shards: 5, runner: "linux.4xlarge.nvidia.gpu" },
          { config: "default", shard: 2, num_shards: 5, runner: "linux.4xlarge.nvidia.gpu" },
          { config: "default", shard: 3, num_shards: 5, runner: "linux.4xlarge.nvidia.gpu" },
          { config: "default", shard: 4, num_shards: 5, runner: "linux.4xlarge.nvidia.gpu" },
          { config: "default", shard: 5, num_shards: 5, runner: "linux.4xlarge.nvidia.gpu" },

          { config: "slow", shard: 1, num_shards: 1, runner: "linux.4xlarge.nvidia.gpu" },

          { config: "slow", shard: 1, num_shards: 2, runner: "linux.4xlarge.nvidia.gpu" },
          { config: "slow", shard: 2, num_shards: 2, runner: "linux.4xlarge.nvidia.gpu" },

          { config: "slow", shard: 1, num_shards: 3, runner: "linux.4xlarge.nvidia.gpu" },
          { config: "slow", shard: 2, num_shards: 3, runner: "linux.4xlarge.nvidia.gpu" },
          { config: "slow", shard: 3, num_shards: 3, runner: "linux.4xlarge.nvidia.gpu" },

          { config: "slow", shard: 1, num_shards: 4, runner: "linux.4xlarge.nvidia.gpu" },
          { config: "slow", shard: 2, num_shards: 4, runner: "linux.4xlarge.nvidia.gpu" },
          { config: "slow", shard: 3, num_shards: 4, runner: "linux.4xlarge.nvidia.gpu" },
          { config: "slow", shard: 4, num_shards: 4, runner: "linux.4xlarge.nvidia.gpu" },

          { config: "slow", shard: 1, num_shards: 5, runner: "linux.4xlarge.nvidia.gpu" },
          { config: "slow", shard: 2, num_shards: 5, runner: "linux.4xlarge.nvidia.gpu" },
          { config: "slow", shard: 3, num_shards: 5, runner: "linux.4xlarge.nvidia.gpu" },
          { config: "slow", shard: 4, num_shards: 5, runner: "linux.4xlarge.nvidia.gpu" },
          { config: "slow", shard: 5, num_shards: 5, runner: "linux.4xlarge.nvidia.gpu" },

          { config: "jit_legacy", shard: 1, num_shards: 1, runner: "linux.4xlarge.nvidia.gpu" },

          { config: "distributed", shard: 1, num_shards: 1, runner: "linux.8xlarge.nvidia.gpu" },

          { config: "distributed", shard: 1, num_shards: 2, runner: "linux.8xlarge.nvidia.gpu" },
          { config: "distributed", shard: 2, num_shards: 2, runner: "linux.8xlarge.nvidia.gpu" },

          { config: "distributed", shard: 1, num_shards: 3, runner: "linux.8xlarge.nvidia.gpu" },
          { config: "distributed", shard: 2, num_shards: 3, runner: "linux.8xlarge.nvidia.gpu" },
          { config: "distributed", shard: 3, num_shards: 3, runner: "linux.8xlarge.nvidia.gpu" },

          { config: "distributed", shard: 1, num_shards: 4, runner: "linux.8xlarge.nvidia.gpu" },
          { config: "distributed", shard: 2, num_shards: 4, runner: "linux.8xlarge.nvidia.gpu" },
          { config: "distributed", shard: 3, num_shards: 4, runner: "linux.8xlarge.nvidia.gpu" },
          { config: "distributed", shard: 4, num_shards: 4, runner: "linux.8xlarge.nvidia.gpu" },

          { config: "distributed", shard: 1, num_shards: 5, runner: "linux.8xlarge.nvidia.gpu" },
          { config: "distributed", shard: 2, num_shards: 5, runner: "linux.8xlarge.nvidia.gpu" },
          { config: "distributed", shard: 3, num_shards: 5, runner: "linux.8xlarge.nvidia.gpu" },
          { config: "distributed", shard: 4, num_shards: 5, runner: "linux.8xlarge.nvidia.gpu" },
          { config: "distributed", shard: 5, num_shards: 5, runner: "linux.8xlarge.nvidia.gpu" },
        ]}

  # please ensure that this and its corresponding job in pull.yml are in sync
  win-vs2019-cuda11_3-py3-build:
    name: win-vs2019-cuda11.3-py3
    uses: ./.github/workflows/_win-build.yml
    with:
      build-environment: win-vs2019-cuda11.3-py3
      cuda-version: "11.3"

  win-vs2019-cuda11_3-py3-test:
    name: win-vs2019-cuda11.3-py3
    uses: ./.github/workflows/_win-test.yml
    needs: win-vs2019-cuda11_3-py3-build
    with:
      build-environment: win-vs2019-cuda11.3-py3
      cuda-version: "11.3"
      test-matrix: |
        { include: [
          { config: "default", shard: 1, num_shards: 1, runner: "windows.8xlarge.nvidia.gpu" },

          { config: "default", shard: 1, num_shards: 2, runner: "windows.8xlarge.nvidia.gpu" },
          { config: "default", shard: 2, num_shards: 2, runner: "windows.8xlarge.nvidia.gpu" },

          { config: "default", shard: 1, num_shards: 3, runner: "windows.8xlarge.nvidia.gpu" },
          { config: "default", shard: 2, num_shards: 3, runner: "windows.8xlarge.nvidia.gpu" },
          { config: "default", shard: 3, num_shards: 3, runner: "windows.8xlarge.nvidia.gpu" },

          { config: "default", shard: 1, num_shards: 4, runner: "windows.8xlarge.nvidia.gpu" },
          { config: "default", shard: 2, num_shards: 4, runner: "windows.8xlarge.nvidia.gpu" },
          { config: "default", shard: 3, num_shards: 4, runner: "windows.8xlarge.nvidia.gpu" },
          { config: "default", shard: 4, num_shards: 4, runner: "windows.8xlarge.nvidia.gpu" },

          { config: "default", shard: 1, num_shards: 5, runner: "windows.8xlarge.nvidia.gpu" },
          { config: "default", shard: 2, num_shards: 5, runner: "windows.8xlarge.nvidia.gpu" },
          { config: "default", shard: 3, num_shards: 5, runner: "windows.8xlarge.nvidia.gpu" },
          { config: "default", shard: 4, num_shards: 5, runner: "windows.8xlarge.nvidia.gpu" },
          { config: "default", shard: 5, num_shards: 5, runner: "windows.8xlarge.nvidia.gpu" },
          { config: "force_on_cpu", shard: 1, num_shards: 1, runner: "windows.4xlarge" },

          { config: "force_on_cpu", shard: 1, num_shards: 2, runner: "windows.4xlarge" },
          { config: "force_on_cpu", shard: 2, num_shards: 2, runner: "windows.4xlarge" },

          { config: "force_on_cpu", shard: 1, num_shards: 3, runner: "windows.4xlarge" },
          { config: "force_on_cpu", shard: 2, num_shards: 3, runner: "windows.4xlarge" },
          { config: "force_on_cpu", shard: 3, num_shards: 3, runner: "windows.4xlarge" },

          { config: "force_on_cpu", shard: 1, num_shards: 4, runner: "windows.4xlarge" },
          { config: "force_on_cpu", shard: 2, num_shards: 4, runner: "windows.4xlarge" },
          { config: "force_on_cpu", shard: 3, num_shards: 4, runner: "windows.4xlarge" },
          { config: "force_on_cpu", shard: 4, num_shards: 4, runner: "windows.4xlarge" },

          { config: "force_on_cpu", shard: 1, num_shards: 5, runner: "windows.4xlarge" },
          { config: "force_on_cpu", shard: 2, num_shards: 5, runner: "windows.4xlarge" },
          { config: "force_on_cpu", shard: 3, num_shards: 5, runner: "windows.4xlarge" },
          { config: "force_on_cpu", shard: 4, num_shards: 5, runner: "windows.4xlarge" },
          { config: "force_on_cpu", shard: 5, num_shards: 5, runner: "windows.4xlarge" },
        ]}
